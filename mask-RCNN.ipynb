{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is for testing only.\n",
      "train:266\n",
      "Val:88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##############################################\n",
    "###    this cell is for dataset setting    ###   \n",
    "##############################################\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import thirdparty.torchvision.detection.utils\n",
    "import utilities.datasets.label_me_dataset\n",
    "\n",
    "dataset_root = './data/dataset'\n",
    "\n",
    "#---setting picture size, please set as same as your data---\n",
    "\n",
    "resized_width = 500\n",
    "resized_height = 600\n",
    "\n",
    "#---setting data form---\n",
    "\n",
    "form = 'bmp'\n",
    "\n",
    "#-----------------------\n",
    "dataset_train_image_root = os.path.join(dataset_root, 'image')\n",
    "dataset_train_mask_root  = os.path.join(dataset_root, 'mask')\n",
    "dataset_val_image_root   = os.path.join(dataset_root, 'val_image')\n",
    "dataset_val_mask_root    = os.path.join(dataset_root, 'val_mask')\n",
    "dataset_test_image_root  = os.path.join(dataset_root, 'test')\n",
    "resized_size = (resized_height, resized_width)\n",
    "transforms = {}\n",
    "\n",
    "#---data transform function, you can set any function you like inside, please refer to pytorch document----\n",
    "\n",
    "transforms['images'] = torchvision.transforms.Compose([torchvision.transforms.Resize(resized_size),\n",
    "                                                       torchvision.transforms.ToTensor(),])\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "transforms['masks'] = torchvision.transforms.Resize(resized_size, PIL.Image.NEAREST)\n",
    "\n",
    "dataset = {}\n",
    "dataset['train'] = utilities.datasets.label_me_dataset.LabelMeDataset(dataset_train_image_root,\n",
    "                                                                      dataset_train_mask_root,\n",
    "                                                                      form,\n",
    "                                                                      transforms['images'],\n",
    "                                                                      transforms['masks'])\n",
    "dataset['val']   = utilities.datasets.label_me_dataset.LabelMeDataset(dataset_val_image_root,\n",
    "                                                                      dataset_val_mask_root,\n",
    "                                                                      form,\n",
    "                                                                      transforms['images'],\n",
    "                                                                      transforms['masks'])\n",
    "dataset['test']  = utilities.datasets.label_me_dataset.LabelMeDataset(dataset_test_image_root,\n",
    "                                                                      None,\n",
    "                                                                      form,\n",
    "                                                                      transforms['images'],\n",
    "                                                                      None)\n",
    "data_loader = {}\n",
    "data_loader['train'] = torch.utils.data.DataLoader(dataset['train'],\n",
    "                                                   batch_size=1,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1,\n",
    "                                                   collate_fn=thirdparty.torchvision.detection.utils.collate_fn)\n",
    "data_loader['val'] = torch.utils.data.DataLoader(dataset['val'],\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=False,\n",
    "                                                 num_workers=1, \n",
    "                                                 collate_fn=thirdparty.torchvision.detection.utils.collate_fn)\n",
    "\n",
    "print('train:' + str(len(data_loader['train'])))\n",
    "print('Val:' + str(len(data_loader['val'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's it!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#######################################################\n",
    "###    this cell is to training function setting    ###   \n",
    "#######################################################\n",
    "\n",
    "import utilities.engine\n",
    "import utilities.models.mask_rcnn\n",
    "import thirdparty.torchvision.detection.engine\n",
    "\n",
    "#---setting training parameters, we only provide mask-RCNN with Resnet50 backbone model now\n",
    "#---for other training function, please refer to Pytorch document--------------------------\n",
    "\n",
    "num_classes = 2\n",
    "model       = utilities.models.mask_rcnn.MaskRCNN(number_classes = num_classes)\n",
    "criterion   = None\n",
    "optimizer   = torch.optim.SGD(params = [p for p in model.parameters() if p.requires_grad],\n",
    "                              lr = 0.005,\n",
    "                              momentum=0.9,\n",
    "                              weight_decay=0.0005) \n",
    "lr_schedule = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "weights     = \"./weights/TSMC_jig_detection.pth\" \n",
    "to_load     = True\n",
    "num_epochs  = 10\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "engine = utilities.engine.Engine(model = model, criterion = criterion, optimizer = optimizer, device = True)\n",
    "# if to_load and os.path.isfile(weights):\n",
    "#     engine.load(weights)\n",
    "# for epoch in range(num_epochs):\n",
    "#     thirdparty.torchvision.detection.engine.train_one_epoch(engine._model,\n",
    "#                                                             engine._optimizer,\n",
    "#                                                             data_loader['train'],\n",
    "#                                                             engine._device,\n",
    "#                                                             epoch,\n",
    "#                                                             print_freq=10)\n",
    "#     lr_schedule.step()\n",
    "#     thirdparty.torchvision.detection.engine.evaluate(engine._model, data_loader['val'], device=engine._device)\n",
    "#     engine.save(weights)\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_outputs() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-795cefd243d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                                              \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                                              \u001b[0mis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                                                                              threshold = threshold)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmasks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance_segmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_masks_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Tim/mask-rcnn_1/utilities/tools/instance_segmentation.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(engine, class_names, inputs, is_tensor, threshold)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_outputs() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "######################################################\n",
    "###    this cell is to visualize testing result    ###   \n",
    "######################################################\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utilities.engine\n",
    "import utilities.tools.general\n",
    "import utilities.tools.instance_segmentation\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "#---put in your trained weight and class name file, then set the shreshold---\n",
    "\n",
    "weights     = './weights/TSMC_jig_detection.pth'\n",
    "class_names = './data/TSMC_Jig_detection.names.txt'\n",
    "threshold   = 0.8  #range:0~0.9, higher means higher score prediction can pass\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "engine.load(weights)\n",
    "image, target = utilities.tools.general.get_random_data(dataset['test'])\n",
    "masks, boxes, labels = utilities.tools.instance_segmentation.get_predictions(engine,\n",
    "                                                                             utilities.tools.general.get_classes(class_names),\n",
    "                                                                             image,\n",
    "                                                                             is_tensor = True,\n",
    "                                                                             threshold = threshold)\n",
    "\n",
    "masks_list = utilities.tools.instance_segmentation.get_masks_polygon(masks)\n",
    "\n",
    "\n",
    "utilities.tools.general.print_predictions_number(len(labels))\n",
    "image = image.mul(255).permute(1, 2, 0).byte().numpy()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "result = utilities.tools.instance_segmentation.get_masked_image(image, (masks, boxes, labels))\n",
    "\n",
    "plt.figure(figsize=(20,30))\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = str(target).lstrip(\"{'image_path'): '\").rstrip(\".bmp'}\")\n",
    "with open(str(target), 'w+') as txt_file:\n",
    "    txt_file.write(str(masks_list))\n",
    "    txt_file.write('\\n')\n",
    "    txt_file.write('lets go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# masks = masks.squeeze()\n",
    "# data_df = pd.DataFrame(masks)\n",
    "\n",
    "# # change the index and column name\n",
    "# data_df.columns = list(range(1,501))\n",
    "# data_df.index = list(range(1,601))\n",
    "\n",
    "\n",
    "# # create and writer pd.DataFrame to excel\n",
    "# writer = pd.ExcelWriter('./masks.xlsx')\n",
    "# data_df.to_excel(writer,'page_1',float_format='%.5f') # float_format 控制精度\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
